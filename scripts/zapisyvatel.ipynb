{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('dictionary.json') as f:\n",
    "    chunks = json.load(f)\n",
    "with open('classes_indices.json') as f:\n",
    "    classes = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aa_or_class\n",
      "{'lex': 'ваӈӄасӄор',\n",
      " 'paradigms': ['N-obl', 'N-nom-0', 'N-pl-t'],\n",
      " 'stem': ['ваӈӄасӄаа', 'ваӈӄасӄаа', 'ваӈӄасӄор', 'ваӈӄасӄаа'],\n",
      " 'trans_ru': 'важенка двух лет'}\n",
      "first_a_class\n",
      "{'lex': 'аатгыр',\n",
      " 'paradigms': ['N-obl', 'N-nom-0', 'N-pl-te'],\n",
      " 'stem': ['аатгыр', 'аатгыр', 'аатгыр', 'аатгыр'],\n",
      " 'trans_ru': '1) ручей в овраге; 2) овраг'}\n",
      "first_a_y_class\n",
      "{'lex': 'вивыт',\n",
      " 'paradigms': ['N-obl', 'N-nom-0', 'N-pl-yt'],\n",
      " 'stem': ['вив%{ы%}т', 'вэвт', 'вивыт', 'вивт'],\n",
      " 'trans_ru': 'китовый ус'}\n",
      "first_b_class\n",
      "{'lex': 'аӈӄы',\n",
      " 'paradigms': ['N-obl', 'N-nom-0', 'N-pl-t'],\n",
      " 'stem': ['аӈӄа', 'аӈӄа', 'аӈӄы', 'аӈӄа'],\n",
      " 'trans_ru': 'море'}\n",
      "first_c_class\n",
      "{'lex': 'айкол',\n",
      " 'paradigms': ['N-obl', 'N-nom-0', 'N-pl-t'],\n",
      " 'stem': ['айколя', 'айколя', 'айкол', 'айколя'],\n",
      " 'trans_ru': 'подстилка '}\n",
      "first_c_ng_to_n_class\n",
      "{'lex': \"э'йӈэвыткунэн\",\n",
      " 'paradigms': ['N-obl', 'N-nom-n', 'N-pl-t'],\n",
      " 'stem': [\"%{Æ%}'йӈ%{Æ%}выткун%{Æ%}ӈ%{Æ%}\",\n",
      "          \"а'йӈавытконаӈа\",\n",
      "          \"э'йӈэвыткунэн\",\n",
      "          \"э'йӈэвыткунэӈэ\"],\n",
      " 'trans_ru': '* рожок; труба (музыкальный инструмент)'}\n",
      "first_g_j_class\n",
      "{'lex': 'ёмромкыӄай',\n",
      " 'paradigms': ['N-obl', 'N-nom-0', 'N-pl-te'],\n",
      " 'stem': ['ёмромкыӄа%{G%}', 'ёмромкыӄаг', 'ёмромкыӄай', 'ёмромкыӄаг'],\n",
      " 'trans_ru': 'куст'}\n",
      "first_n_ending_class\n",
      "{'lex': 'айголяткэгыргын',\n",
      " 'paradigms': ['N-obl', 'N-nom-n', 'N-pl'],\n",
      " 'stem': ['айголяткэгыргын',\n",
      "          'айголяткэгыргын',\n",
      "          'айголяткэгыргын',\n",
      "          'айголяткэгыргын'],\n",
      " 'trans_ru': 'невежество'}\n",
      "five_v_class\n",
      "{'lex': 'авээн',\n",
      " 'paradigms': ['N-obl', 'N-nom-0', 'N-pl-yt'],\n",
      " 'stem': ['авээнв', 'авээнв', 'авээн', 'авээнв'],\n",
      " 'trans_ru': 'пастбище'}\n",
      "five_v_reduced_class\n",
      "{'lex': 'агнотваны',\n",
      " 'paradigms': ['N-obl', 'N-nom-0', 'N-pl-yt'],\n",
      " 'stem': ['агнотванв', 'агнотванв', 'агнотваны', 'агнотванв'],\n",
      " 'trans_ru': 'лежбище моржей'}\n",
      "lyngyn_class\n",
      "{'lex': 'апаапаглыӈын',\n",
      " 'paradigms': ['N-obl', 'N-nom-n', 'N-pl-ti'],\n",
      " 'stem': ['%{Æ%}п%{Æ%}%{Æ%}п%{Æ%}г', 'апаапаг', 'апаапаглыӈ', 'эпээпэг'],\n",
      " 'trans_ru': 'паук'}\n",
      "lyngyn_g_j_class\n",
      "{'lex': 'ӈойӈойлыӈын',\n",
      " 'paradigms': ['N-obl', 'N-nom-n', 'N-pl-ti'],\n",
      " 'stem': ['ӈуйӈу%{G%}', 'ӈойӈог', 'ӈойӈой', 'ӈуйӈуг'],\n",
      " 'trans_ru': 'шерстинка'}\n",
      "ngy_class\n",
      "{'lex': 'аръапаӈы',\n",
      " 'paradigms': ['N-obl', 'N-nom-0', 'N-pl-t'],\n",
      " 'stem': ['аръапа', 'аръапа', 'аръапа', 'аръапа'],\n",
      " 'trans_ru': 'бульон'}\n",
      "qorangy_class\n",
      "{'lex': 'ӄораӈы',\n",
      " 'paradigms': ['N-obl', 'N-nom-0', 'N-pl-t'],\n",
      " 'stem': ['ӄаа', 'ӄаа', 'ӄора', 'ӄаа'],\n",
      " 'trans_ru': 'олень'}\n",
      "second_a_full_redup_class\n",
      "{'lex': 'виилвиил',\n",
      " 'paradigms': ['N-obl', 'N-nom-0', 'N-pl-ti'],\n",
      " 'stem': ['виил', 'вээл', 'виилвиил', 'виил'],\n",
      " 'trans_ru': 'тень'}\n",
      "second_b_redup_wo_last_letter_class\n",
      "{'lex': 'вайпывай',\n",
      " 'paradigms': ['N-obl', 'N-nom-0', 'N-pl-yt'],\n",
      " 'stem': ['вайп', 'вайп', 'вайпывай', 'вайп'],\n",
      " 'trans_ru': 'деревянная игла для вязки сетей'}\n",
      "singulative_class\n",
      "{'lex': 'аёпычьылгын',\n",
      " 'paradigms': ['N-obl', 'N-nom-lgyn', 'N-pl-yt'],\n",
      " 'stem': ['%{Æ%}юпычь', 'аёпычь', 'аёпычьы', 'эюпычь'],\n",
      " 'trans_ru': 'колючка'}\n",
      "strange_star_first_a_class\n",
      "{'lex': 'ваарват *',\n",
      " 'paradigms': ['N-obl', 'N-nom-0', 'N-pl-te'],\n",
      " 'stem': ['ваарват', 'ваарват', 'ваарват', 'ваарват'],\n",
      " 'trans_ru': '1) тетива; 2) прямая линия, соединяющая концы кривой'}\n",
      "strange_star_singulative_class\n",
      "{'lex': 'этъычьылгын*',\n",
      " 'paradigms': ['N-obl', 'N-nom-0', 'N-pl-yt'],\n",
      " 'stem': ['итъычь', 'этъычь', 'этъычьылгын*', 'итъычь'],\n",
      " 'trans_ru': 'мелкий голец (рыба)'}\n",
      "strange_star_third_class\n",
      "{'lex': 'атанмыргын *',\n",
      " 'paradigms': ['N-obl', 'N-nom-0', 'N-pl'],\n",
      " 'stem': ['атанмырг', 'атанмырг', 'атанмырг', 'атанмырыгрыг'],\n",
      " 'trans_ru': 'грива (лошади)'}\n",
      "strange_yn_except_absolutive_class\n",
      "{'lex': 'вагыткын',\n",
      " 'paradigms': ['N-obl', 'N-nom-n', 'N-pl-te'],\n",
      " 'stem': ['вагыткын', 'вагыткын', 'вагытк', 'вагыткын'],\n",
      " 'trans_ru': 'почка (у растения)'}\n",
      "third_class\n",
      "{'lex': 'авынральын',\n",
      " 'paradigms': ['N-obl', 'N-nom-n', 'N-pl-t'],\n",
      " 'stem': ['авынраль', 'авынраль', 'авынраль', 'авынраль'],\n",
      " 'trans_ru': 'хозяин'}\n",
      "third_or_five_v_class\n",
      "{'lex': 'анольатын',\n",
      " 'paradigms': ['N-obl', 'N-nom-n', 'N-pl-yt'],\n",
      " 'stem': ['анольатынв', 'анольатынв', 'анольат', 'анольатынв'],\n",
      " 'trans_ru': 'летнее место пребывания кочевников'}\n"
     ]
    }
   ],
   "source": [
    "cls_order = sorted(classes.keys())\n",
    "for cls in cls_order:\n",
    "    print(cls)\n",
    "    pprint(chunks[classes[cls][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aa_or_class',\n",
      " 'first_a_class',\n",
      " 'first_a_y_class',\n",
      " 'first_b_class',\n",
      " 'first_c_class',\n",
      " 'first_c_ng_to_n_class',\n",
      " 'first_g_j_class',\n",
      " 'first_n_ending_class',\n",
      " 'five_v_class',\n",
      " 'five_v_reduced_class',\n",
      " 'lyngyn_class',\n",
      " 'lyngyn_g_j_class',\n",
      " 'ngy_class',\n",
      " 'qorangy_class',\n",
      " 'second_a_full_redup_class',\n",
      " 'second_b_redup_wo_last_letter_class',\n",
      " 'singulative_class',\n",
      " 'strange_star_first_a_class',\n",
      " 'strange_star_singulative_class',\n",
      " 'strange_star_third_class',\n",
      " 'strange_yn_except_absolutive_class',\n",
      " 'third_class',\n",
      " 'third_or_five_v_class']\n"
     ]
    }
   ],
   "source": [
    "pprint(cls_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "folder = 'lexicons'\n",
    "if not os.path.exists(os.path.join('..', folder)):\n",
    "    os.mkdir(os.path.join('..', folder))\n",
    "\n",
    "dict_file = 'nominals.lexc'\n",
    "with open(os.path.join('..', folder, dict_file), 'w') as f:\n",
    "    f.write(\"\"\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "!!!                          L E X I C O N                                  !!!\n",
    "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "\"\"\")\n",
    "    f.write(\"\"\"\n",
    "LEXICON Nouns \n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# разметить архифонемы и loan phonology\n",
    "# архифонемы - Æ и G\n",
    "# G в g_j, Æ везде\n",
    "\n",
    "# Æ\n",
    "recessive = set('уюи')\n",
    "dominant = set('аояё')\n",
    "\n",
    "for i in range(len(chunks)):\n",
    "    if set(chunks[i]['stem'][0])&recessive or (set(chunks[i]['stem'][1])&dominant and not set(chunks[i]['stem'][0])&dominant):\n",
    "        if 'э' in chunks[i]['stem'][0]:\n",
    "            chunks[i]['stem'][0] = chunks[i]['stem'][0].replace('э', '%{Æ%}') # 0 bcs i will take 0 as stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# G\n",
    "for i in classes['first_g_j_class']+classes['lyngyn_g_j_class']:\n",
    "    chunks[i]['stem'][0] = chunks[i]['stem'][0][:-1]+'%{G%}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# epenthesis\n",
    "for i in classes['first_a_y_class']:\n",
    "    chunks[i]['stem'][0] = chunks[i]['stem'][0][:-1]+'%{ы%}'+chunks[i]['stem'][0][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lex': 'вивыт',\n",
       " 'paradigms': ['N-obl', 'N-nom-0', 'N-pl-yt'],\n",
       " 'stem': ['вив%{ы%}т', 'вэвт', 'вивыт', 'вивт'],\n",
       " 'trans_ru': 'китовый ус'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[220]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# oops\n",
    "\n",
    "for i in range(len(chunks)):\n",
    "    chunks[i]['lex'] = chunks[i]['lex'].replace('ң', 'ӈ')\n",
    "    chunks[i]['lex'] = chunks[i]['lex'].replace('қ', 'ӄ')\n",
    "    chunks[i]['stem'] = list(map(lambda x: x.replace('ң', 'ӈ'), chunks[i]['stem']))\n",
    "    chunks[i]['stem'] = list(map(lambda x: x.replace('қ', 'ӄ'), chunks[i]['stem']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('dictionary.json', 'w') as f:\n",
    "    json.dump(chunks, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "to_write = []\n",
    "for i in classes['first_a_class']+classes['first_a_y_class']+classes['first_g_j_class']+classes['first_c_ng_to_n_class']:\n",
    "    x = chunks[i]\n",
    "    to_write.append('{}:{} N-Ia-AATGYR ;    ! {}'.format(x['lex'], x['stem'][0], x['trans_ru']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in classes['first_b_class']:\n",
    "    x = chunks[i]\n",
    "    to_write.append('{}:{} N-Ib-ANGKY ;    ! {}'.format(x['lex'], x['stem'][0], x['trans_ru']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in classes['first_c_class']:\n",
    "    x = chunks[i]\n",
    "    to_write.append('{}:{} N-Ic-AJKOL ;    ! {}'.format(x['lex'], x['stem'][0], x['trans_ru']))\n",
    "to_write.append('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in classes['second_a_full_redup_class']:\n",
    "    x = chunks[i]\n",
    "    to_write.append('{}:{} N-IIa-VIIL-ABS ;    ! {}'.format(x['lex'], x['stem'][2], x['trans_ru']))\n",
    "    to_write.append('{}:{} N-IIa-VIIL-OBL ;    ! {}'.format(x['lex'], x['stem'][0], x['trans_ru']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in classes['second_b_redup_wo_last_letter_class']:\n",
    "    x = chunks[i]\n",
    "    to_write.append('{}:{} N-IIb-VAJP-ABS ;    ! {}'.format(x['lex'], x['stem'][2], x['trans_ru']))\n",
    "    to_write.append('{}:{} N-IIb-VAJP-OBL ;    ! {}'.format(x['lex'], x['stem'][0], x['trans_ru']))\n",
    "to_write.append('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in classes['third_class']:\n",
    "    x = chunks[i]\n",
    "    to_write.append('{}:{} N-III-AVYNRAL ;    ! {}'.format(x['lex'], x['stem'][0], x['trans_ru']))\n",
    "to_write.append('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in classes['ngy_class']:\n",
    "    x = chunks[i]\n",
    "    to_write.append('{}:{} N-IV-ARAPA ;    ! {}'.format(x['lex'], x['stem'][0], x['trans_ru']))\n",
    "\n",
    "for i in classes['qorangy_class']:\n",
    "    x = chunks[i]\n",
    "    to_write.append('{}:{} N-IV-QORA-ABS ;    ! {}'.format(x['lex'], x['stem'][2], x['trans_ru']))\n",
    "    to_write.append('{}:{} N-IV-QORA-OBL ;    ! {}'.format(x['lex'], x['stem'][0], x['trans_ru']))\n",
    "\n",
    "to_write.append('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in classes['five_v_class']:\n",
    "    x = chunks[i]\n",
    "    to_write.append('{}:{} N-Vv-AVEEN ;    ! {}'.format(x['lex'], x['stem'][0][:-1], x['trans_ru']))\n",
    "\n",
    "for i in classes['five_v_reduced_class']:\n",
    "    x = chunks[i]\n",
    "    to_write.append('{}:{} N-Vvy-AGNOTVAN ;    ! {}'.format(x['lex'], x['stem'][0][:-1], x['trans_ru']))\n",
    "    \n",
    "to_write.append('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in classes['singulative_class']:\n",
    "    x = chunks[i]\n",
    "    to_write.append('{}:{} N-SING-AYOPYCH ;    ! {}'.format(x['lex'], x['stem'][0], x['trans_ru']))\n",
    "to_write.append('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in classes['lyngyn_class']+classes['lyngyn_g_j_class']:\n",
    "    x = chunks[i]\n",
    "    to_write.append('{}:{} N-LYNG-EPEEPEG ;    ! {}'.format(x['lex'], x['stem'][0], x['trans_ru']))\n",
    "to_write.append('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in classes['aa_or_class']:\n",
    "    x = chunks[i]\n",
    "    to_write.append('{}:{} N-VANGQASQOR ;    ! {}'.format(x['lex'], x['stem'][0], x['trans_ru']))\n",
    "to_write.append('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "725"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(to_write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(os.path.join('..', folder, dict_file), 'a') as f:\n",
    "    f.write('\\n'.join(to_write))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
