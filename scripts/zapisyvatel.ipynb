{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('dictionary.json') as f:\n",
    "    chunks = json.load(f)\n",
    "with open('classes_indices.json') as f:\n",
    "    classes = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aa_or_class\n",
      "{'lex': 'ваңқасқор',\n",
      " 'paradigms': ['N-obl', 'N-nom-0', 'N-pl-t'],\n",
      " 'stem': ['ваңқасқаа', 'ваңқасқаа', 'ваңқасқор', 'ваңқасқаа'],\n",
      " 'trans_ru': 'важенка двух лет'}\n",
      "first_a_class\n",
      "{'lex': 'аатгыр',\n",
      " 'paradigms': ['N-obl', 'N-nom-0', 'N-pl-te'],\n",
      " 'stem': ['аатгыр', 'аатгыр', 'аатгыр', 'аатгыр'],\n",
      " 'trans_ru': '1) ручей в овраге; 2) овраг'}\n",
      "first_a_g_j_class\n",
      "{'lex': 'ёмромкықай',\n",
      " 'paradigms': ['N-obl', 'N-nom-0', 'N-pl-te'],\n",
      " 'stem': ['ёмромкықаг', 'ёмромкықаг', 'ёмромкықай', 'ёмромкықаг'],\n",
      " 'trans_ru': 'куст'}\n",
      "first_a_y_class\n",
      "{'lex': 'вивыт',\n",
      " 'paradigms': ['N-obl', 'N-nom-0', 'N-pl-yt'],\n",
      " 'stem': ['вивт', 'вэвт', 'вивыт', 'вивт'],\n",
      " 'trans_ru': 'китовый ус'}\n",
      "first_a_y_n_to_ng_class\n",
      "{'lex': 'йыңыр',\n",
      " 'paradigms': ['N-obl', 'N-nom-0', 'N-pl-yt'],\n",
      " 'stem': ['йынр', 'йынр', 'йыңыр', 'йынр'],\n",
      " 'trans_ru': '(2) высокий обрывистый берег'}\n",
      "first_b_class\n",
      "{'lex': 'аңқы',\n",
      " 'paradigms': ['N-obl', 'N-nom-0', 'N-pl-t'],\n",
      " 'stem': ['аңқа', 'аңқа', 'аңқы', 'аңқа'],\n",
      " 'trans_ru': 'море'}\n",
      "first_c_class\n",
      "{'lex': 'айкол',\n",
      " 'paradigms': ['N-obl', 'N-nom-0', 'N-pl-t'],\n",
      " 'stem': ['айколя', 'айколя', 'айкол', 'айколя'],\n",
      " 'trans_ru': 'подстилка '}\n",
      "first_c_ng_to_n_class\n",
      "{'lex': \"э'йңэвыткунэн\",\n",
      " 'paradigms': ['N-obl', 'N-nom-n', 'N-pl-t'],\n",
      " 'stem': [\"э'йңэвыткунэңэ\",\n",
      "          \"а'йңавытконаңа\",\n",
      "          \"э'йңэвыткунэн\",\n",
      "          \"э'йңэвыткунэңэ\"],\n",
      " 'trans_ru': '* рожок; труба (музыкальный инструмент)'}\n",
      "first_n_ending_class\n",
      "{'lex': 'айголяткэгыргын',\n",
      " 'paradigms': ['N-obl', 'N-nom-n', 'N-pl'],\n",
      " 'stem': ['айголяткэгыргын',\n",
      "          'айголяткэгыргын',\n",
      "          'айголяткэгыргын',\n",
      "          'айголяткэгыргын'],\n",
      " 'trans_ru': 'невежество'}\n",
      "five_v_class\n",
      "{'lex': 'авээн',\n",
      " 'paradigms': ['N-obl', 'N-nom-0', 'N-pl-yt'],\n",
      " 'stem': ['авээнв', 'авээнв', 'авээн', 'авээнв'],\n",
      " 'trans_ru': 'пастбище'}\n",
      "five_v_reduced_class\n",
      "{'lex': 'агнотваны',\n",
      " 'paradigms': ['N-obl', 'N-nom-0', 'N-pl-yt'],\n",
      " 'stem': ['агнотванв', 'агнотванв', 'агнотваны', 'агнотванв'],\n",
      " 'trans_ru': 'лежбище моржей'}\n",
      "fourth_class\n",
      "{'lex': 'аръапаңы',\n",
      " 'paradigms': ['N-obl', 'N-nom-0', 'N-pl-t'],\n",
      " 'stem': ['аръапа', 'аръапа', 'аръапа', 'аръапа'],\n",
      " 'trans_ru': 'бульон'}\n",
      "fourth_or_class\n",
      "{'lex': 'қораңы',\n",
      " 'paradigms': ['N-obl', 'N-nom-0', 'N-pl-t'],\n",
      " 'stem': ['қаа', 'қаа', 'қора', 'қаа'],\n",
      " 'trans_ru': 'олень'}\n",
      "second_a_full_redup_class\n",
      "{'lex': 'виилвиил',\n",
      " 'paradigms': ['N-obl', 'N-nom-0', 'N-pl-ti'],\n",
      " 'stem': ['виил', 'вээл', 'виилвиил', 'виил'],\n",
      " 'trans_ru': 'тень'}\n",
      "second_b_redup_wo_last_letter_class\n",
      "{'lex': \"а'рэа'р\",\n",
      " 'paradigms': ['N-obl', 'N-nom-0', 'N-pl-t'],\n",
      " 'stem': [\"а'рэ\", \"а'рэ\", \"а'рэа'р\", \"а'рэ\"],\n",
      " 'trans_ru': 'торос, см. каалгын'}\n",
      "singulative_lgyn_class\n",
      "{'lex': 'аёпычьылгын',\n",
      " 'paradigms': ['N-obl', 'N-nom-lgyn', 'N-pl-yt'],\n",
      " 'stem': ['эюпычь', 'аёпычь', 'аёпычьы', 'эюпычь'],\n",
      " 'trans_ru': 'колючка'}\n",
      "singulative_lyng_class\n",
      "{'lex': 'апаапаглыңын',\n",
      " 'paradigms': ['N-obl', 'N-nom-n', 'N-pl-ti'],\n",
      " 'stem': ['эпээпэг', 'апаапаг', 'апаапаглың', 'эпээпэг'],\n",
      " 'trans_ru': 'паук'}\n",
      "singulative_lyng_g_j_class\n",
      "{'lex': 'ңойңойлыңын',\n",
      " 'paradigms': ['N-obl', 'N-nom-n', 'N-pl-ti'],\n",
      " 'stem': ['ңуйңуг', 'ңойңог', 'ңойңой', 'ңуйңуг'],\n",
      " 'trans_ru': 'шерстинка'}\n",
      "strange_star_first_a_class\n",
      "{'lex': 'ваарват',\n",
      " 'paradigms': ['N-obl', 'N-nom-0', 'N-pl-te'],\n",
      " 'stem': ['ваарват', 'ваарват', 'ваарват', 'ваарват'],\n",
      " 'trans_ru': '1) тетива; 2) прямая линия, соединяющая концы кривой'}\n",
      "strange_star_singulative_class\n",
      "{'lex': 'этъычьылгын',\n",
      " 'paradigms': ['N-obl', 'N-nom-0', 'N-pl-yt'],\n",
      " 'stem': ['итъычь', 'этъычь', 'этъычьылгын', 'итъычь'],\n",
      " 'trans_ru': 'мелкий голец (рыба)'}\n",
      "strange_star_third_class\n",
      "{'lex': 'атанмыргын',\n",
      " 'paradigms': ['N-obl', 'N-nom-0', 'N-pl'],\n",
      " 'stem': ['атанмырг', 'атанмырг', 'атанмырг', 'атанмырыгрыг'],\n",
      " 'trans_ru': 'грива (лошади)'}\n",
      "strange_third_class\n",
      "{'lex': 'айылгыгыргын',\n",
      " 'paradigms': [],\n",
      " 'stem': ['айылгыгырг', 'айылгыгырг', 'айылгыгырг', 'айылгыгырг'],\n",
      " 'trans_ru': '1. боязнь; 2. страшный'}\n",
      "strange_yn_except_absolutive_class\n",
      "{'lex': 'вагыткын',\n",
      " 'paradigms': ['N-obl', 'N-nom-n', 'N-pl-te'],\n",
      " 'stem': ['вагыткын', 'вагыткын', 'вагытк', 'вагыткын'],\n",
      " 'trans_ru': 'почка (у растения)'}\n",
      "third_class\n",
      "{'lex': 'авынральын',\n",
      " 'paradigms': ['N-obl', 'N-nom-n', 'N-pl-t'],\n",
      " 'stem': ['авынраль', 'авынраль', 'авынраль', 'авынраль'],\n",
      " 'trans_ru': 'хозяин'}\n",
      "third_false_lgyn_class\n",
      "{'lex': 'вутилгын',\n",
      " 'paradigms': ['N-obl', 'N-nom-lgyn', 'N-pl'],\n",
      " 'stem': ['вути', 'вотэ', 'вути', 'вути'],\n",
      " 'trans_ru': 'верёвка для привязи собак'}\n",
      "third_or_five_v_class\n",
      "{'lex': 'анольатын',\n",
      " 'paradigms': ['N-obl', 'N-nom-n', 'N-pl-yt'],\n",
      " 'stem': ['анольатынв', 'анольатынв', 'анольат', 'анольатынв'],\n",
      " 'trans_ru': 'летнее место пребывания кочевников'}\n"
     ]
    }
   ],
   "source": [
    "cls_order = sorted(classes.keys())\n",
    "for cls in cls_order:\n",
    "    print(cls)\n",
    "    pprint(chunks[classes[cls][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aa_or_class',\n",
      " 'first_a_class',\n",
      " 'first_a_g_j_class',\n",
      " 'first_a_y_class',\n",
      " 'first_a_y_n_to_ng_class',\n",
      " 'first_b_class',\n",
      " 'first_c_class',\n",
      " 'first_c_ng_to_n_class',\n",
      " 'first_n_ending_class',\n",
      " 'five_v_class',\n",
      " 'five_v_reduced_class',\n",
      " 'fourth_class',\n",
      " 'fourth_or_class',\n",
      " 'second_a_full_redup_class',\n",
      " 'second_b_redup_wo_last_letter_class',\n",
      " 'singulative_lgyn_class',\n",
      " 'singulative_lyng_class',\n",
      " 'singulative_lyng_g_j_class',\n",
      " 'strange_star_first_a_class',\n",
      " 'strange_star_singulative_class',\n",
      " 'strange_star_third_class',\n",
      " 'strange_third_class',\n",
      " 'strange_yn_except_absolutive_class',\n",
      " 'third_class',\n",
      " 'third_false_lgyn_class',\n",
      " 'third_or_five_v_class']\n"
     ]
    }
   ],
   "source": [
    "pprint(cls_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "folder = 'lexicons'\n",
    "if not os.path.exists(os.path.join('..', folder)):\n",
    "    os.mkdir(os.path.join('..', folder))\n",
    "\n",
    "dict_file = 'nominals.lexc'\n",
    "with open(os.path.join('..', folder, dict_file), 'w') as f:\n",
    "    f.write(\"\"\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "!!!                          L E X I C O N                                  !!!\n",
    "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "\"\"\")\n",
    "    f.write(\"\"\"\n",
    "LEXICON Nouns \n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# loan phonology\n",
    "\n",
    "russ = 'январь февраль март апрель май июнь июль август сентябрь октябрь декабрь билет бригада бригадир буква \\\n",
    "понедельник вторник среда четверг пятница суббота воскресенье тетрадь ңэвучитель округ пионер революция порядка \\\n",
    "электричество элетростанция электроаак чернилаёчгын энанвалёматпункт'.split()\n",
    "\n",
    "for i in range(len(chunks)):\n",
    "    if chunks[i]['lex'] in russ:\n",
    "        chunks[i]['stem'][0] = chunks[i]['stem'][0]+'%{☭%}'\n",
    "\n",
    "#     for st in chunks[i]['stem']:\n",
    "#         if set(st)&recessive and set(st)&dominant:\n",
    "#             chunks[i]['stem'] = list(map(lambda x: x+'%{☭%}', chunks[i]['stem']))\n",
    "#             break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# разметить архифонемы и loan phonology\n",
    "# архифонемы - Æ и G\n",
    "# G в g_j, Æ везде\n",
    "\n",
    "# Æ\n",
    "recessive = set('уюи')\n",
    "dominant = set('аояё')\n",
    "\n",
    "for i in range(len(chunks)):\n",
    "    if not '☭' in chunks[i]['stem'][0]:\n",
    "        if set(chunks[i]['stem'][0])&recessive or (set(chunks[i]['stem'][1])&dominant and not set(chunks[i]['stem'][0])&dominant):\n",
    "            if 'э' in chunks[i]['stem'][0]:\n",
    "                chunks[i]['stem'][0] = chunks[i]['stem'][0].replace('э', '%{Æ%}') # 0 bcs i will take 0 as stem\n",
    "            elif 'ле' in chunks[i]['stem'][0]:\n",
    "                chunks[i]['stem'][0] = chunks[i]['stem'][0].replace('е', '%{Æ%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# G\n",
    "for i in classes['first_a_g_j_class']+classes['singulative_lyng_g_j_class']:\n",
    "    chunks[i]['stem'][0] = chunks[i]['stem'][0][:-1]+'%{G%}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# N\n",
    "for i in classes['first_a_y_n_to_ng_class']+classes['first_c_ng_to_n_class']:\n",
    "    chunks[i]['stem'][0] = chunks[i]['stem'][0][:-2]+'%{N%}'+chunks[i]['stem'][0][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# epenthesis\n",
    "cons = 'йцкнгшщзхъждлрпвфчсмтьбңқ'\n",
    "for i in range(len(chunks)):\n",
    "    if not '☭' in chunks[i]['stem'][0]:\n",
    "        if chunks[i]['stem'][0][-1] in cons and chunks[i]['stem'][0][-2] in cons:\n",
    "            chunks[i]['stem'][0] = chunks[i]['stem'][0][:-1]+'%{ы%}'+chunks[i]['stem'][0][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lex': 'вивыт',\n",
       " 'paradigms': ['N-obl', 'N-nom-0', 'N-pl-yt'],\n",
       " 'stem': ['вив%{ы%}т', 'вэвт', 'вивыт', 'вивт'],\n",
       " 'trans_ru': 'китовый ус'}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[220]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# oops\n",
    "\n",
    "for i in range(len(chunks)):\n",
    "    chunks[i]['lex'] = chunks[i]['lex'].replace('ң', 'ӈ')\n",
    "    chunks[i]['lex'] = chunks[i]['lex'].replace('қ', 'ӄ')\n",
    "    chunks[i]['lex'] = chunks[i]['lex'].replace('л', 'ԓ')\n",
    "    chunks[i]['lex'] = chunks[i]['lex'].replace(\"'\", 'ʼ')\n",
    "    chunks[i]['stem'] = list(map(lambda x: x.replace('ң', 'ӈ'), chunks[i]['stem']))\n",
    "    chunks[i]['stem'] = list(map(lambda x: x.replace('қ', 'ӄ'), chunks[i]['stem']))\n",
    "    chunks[i]['stem'] = list(map(lambda x: x.replace('л', 'ԓ'), chunks[i]['stem']))\n",
    "    chunks[i]['stem'] = list(map(lambda x: x.replace(\"'\", 'ʼ'), chunks[i]['stem']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# with open('dictionary.json', 'w') as f:\n",
    "#     json.dump(chunks, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "to_write = []\n",
    "for i in classes['first_a_class']+classes['first_a_y_class']+classes['first_a_g_j_class']:\n",
    "    x = chunks[i]\n",
    "    to_write.append('{}:{} N-Ia-AATGYR ;    ! {}'.format(x['lex'], x['stem'][0], x['trans_ru']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in classes['first_a_y_n_to_ng_class']:\n",
    "    x = chunks[i]\n",
    "    to_write.append('{}:{} N-Ia-JYNYR-ABS ;    ! {}'.format(x['lex'], x['stem'][2], x['trans_ru']))\n",
    "    to_write.append('{}:{} N-OBL ;    ! {}'.format(x['lex'], x['stem'][0], x['trans_ru']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in classes['first_b_class']:\n",
    "    x = chunks[i]\n",
    "    to_write.append('{}:{} N-Ib-ANGKY ;    ! {}'.format(x['lex'], x['stem'][0], x['trans_ru']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in classes['first_c_class']:\n",
    "    x = chunks[i]\n",
    "    to_write.append('{}:{} N-Ic-AJKOL ;    ! {}'.format(x['lex'], x['stem'][0], x['trans_ru']))\n",
    "to_write.append('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in classes['first_c_ng_to_n_class']:\n",
    "    x = chunks[i]\n",
    "    to_write.append('{}:{} N-Ic-EJNETKUNEN-ABS ;    ! {}'.format(x['lex'], x['stem'][2], x['trans_ru']))\n",
    "    to_write.append('{}:{} N-OBL ;    ! {}'.format(x['lex'], x['stem'][0], x['trans_ru']))\n",
    "to_write.append('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in classes['second_a_full_redup_class']:\n",
    "    x = chunks[i]\n",
    "    to_write.append('{}:{} N-IIa-VIIL-ABS ;    ! {}'.format(x['lex'], x['stem'][2], x['trans_ru']))\n",
    "    to_write.append('{}:{} N-OBL ;    ! {}'.format(x['lex'], x['stem'][0], x['trans_ru']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in classes['second_b_redup_wo_last_letter_class']:\n",
    "    x = chunks[i]\n",
    "    to_write.append('{}:{} N-IIb-VAJP-ABS ;    ! {}'.format(x['lex'], x['stem'][2], x['trans_ru']))\n",
    "    to_write.append('{}:{} N-OBL ;    ! {}'.format(x['lex'], x['stem'][0], x['trans_ru']))\n",
    "to_write.append('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in classes['third_class']:\n",
    "    x = chunks[i]\n",
    "    to_write.append('{}:{} N-III-AVYNRAL ;    ! {}'.format(x['lex'], x['stem'][0], x['trans_ru']))\n",
    "\n",
    "\n",
    "for i in classes['third_false_lgyn_class']:\n",
    "    x = chunks[i]\n",
    "    to_write.append('{}:{}ԓг N-III-AVYNRAL ;    ! {}'.format(x['lex'], x['stem'][0], x['trans_ru']))\n",
    "to_write.append('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in classes['fourth_class']:\n",
    "    x = chunks[i]\n",
    "    to_write.append('{}:{} N-IV-ARAPA ;    ! {}'.format(x['lex'], x['stem'][0], x['trans_ru']))\n",
    "\n",
    "for i in classes['fourth_or_class']:\n",
    "    x = chunks[i]\n",
    "    to_write.append('{}:{} N-IV-QORA-ABS ;    ! {}'.format(x['lex'], x['stem'][2], x['trans_ru']))\n",
    "    to_write.append('{}:{} N-OBL ;    ! {}'.format(x['lex'], x['stem'][0], x['trans_ru']))\n",
    "\n",
    "to_write.append('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in classes['five_v_class']:\n",
    "    x = chunks[i]\n",
    "    to_write.append('{}:{} N-Vv-AVEEN ;    ! {}'.format(x['lex'], x['stem'][0][:-1], x['trans_ru']))\n",
    "\n",
    "for i in classes['five_v_reduced_class']:\n",
    "    x = chunks[i]\n",
    "    to_write.append('{}:{} N-Vvy-AGNOTVAN ;    ! {}'.format(x['lex'], x['stem'][0][:-1], x['trans_ru']))\n",
    "    \n",
    "to_write.append('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in classes['singulative_lgyn_class']:\n",
    "    x = chunks[i]\n",
    "    to_write.append('{}:{} N-SING-AJOPYCH ;    ! {}'.format(x['lex'], x['stem'][0], x['trans_ru']))\n",
    "to_write.append('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in classes['singulative_lyng_class']+classes['singulative_lyng_g_j_class']:\n",
    "    x = chunks[i]\n",
    "    to_write.append('{}:{} N-SING-EPEEPEG ;    ! {}'.format(x['lex'], x['stem'][0], x['trans_ru']))\n",
    "to_write.append('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in classes['aa_or_class']:\n",
    "    x = chunks[i]\n",
    "    to_write.append('{}:{} N-VANGQASQOR-ABS ;    ! {}'.format(x['lex'], x['stem'][2], x['trans_ru']))\n",
    "    to_write.append('{}:{} N-OBL ;    ! {}'.format(x['lex'], x['stem'][0], x['trans_ru']))\n",
    "to_write.append('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "to_write.append('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "to_write.append('! this one may be III \\n')\n",
    "for i in classes['first_n_ending_class']:\n",
    "    x = chunks[i]\n",
    "    to_write.append('{}:{} N-Ia-AATGYR ;    ! {}'.format(x['lex'], x['stem'][0], x['trans_ru']))\n",
    "to_write.append('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "to_write.append('! either Vv or III \\n')\n",
    "for i in classes['third_or_five_v_class']:\n",
    "    x = chunks[i]\n",
    "    to_write.append('{}:{} N-Vv-AVEEN ;    ! {}'.format(x['lex'], x['stem'][0][:-1], x['trans_ru']))\n",
    "to_write.append('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "to_write.append('! this one may be III \\n')\n",
    "for i in classes['strange_yn_except_absolutive_class']:\n",
    "    x = chunks[i]\n",
    "    to_write.append('{}:{} N-Ia-AATGYR ;    ! {}'.format(x['lex'], x['stem'][0], x['trans_ru']))\n",
    "to_write.append('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "to_write.append('! either third or sing, either ending with ы or not \\n')\n",
    "for i in classes['strange_third_class']:\n",
    "    x = chunks[i]\n",
    "    to_write.append('{}:{} N-III-AVYNRAL ;    ! {}'.format(x['lex'], x['stem'][0], x['trans_ru']))\n",
    "to_write.append('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2388"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(to_write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(os.path.join('..', folder, dict_file), 'a') as f:\n",
    "    f.write('\\n'.join(to_write))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8772961058045555"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(to_write)/len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
